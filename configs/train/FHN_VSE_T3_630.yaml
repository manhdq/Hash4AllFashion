data_param:
  batch_size: 2 # batch size
  data_root: /home/ubuntu/Documents/working/Hangers.AI/data/hash4all_polyvore # data root
  image_root: /home/ubuntu/Documents/working/Hangers.AI/data/hash4all_polyvore # image root
  data_set: tuples_630 # data set
  nega_mode: RandomOnline # negative outfits strategy
  num_workers: 2 # number of workers
  use_lmdb: true # use lmbd data
  use_semantic: false # use sentance data
  use_visual: true # use visual data

train_data_param:
  shuffle: true # do shuffle
  data_mode: PairWise # output data format
  phase: train # split

test_data_param:
  shuffle: false # do not shuffle
  data_mode: PairWise # output data format
  phase: val # split

net_param:
  name: FashionNet
  num_users: 630 # number of users
  dim: 128 # dimension of binary codes
  backbone: alexnet # backbone for feature extractor
  hash_types: 3 # type of hash codes
  scale_tanh: true # use scale tahn
  use_semantic: true # use semantic features
  use_visual: true # user visdual features
  margin: 0.1 # margin for vse-loss, if exists

solver_param:
  name: "FashionNetSolver"
  display: 20 # display interval
  epochs: 100 # total epoches
  gamma: 1.0 # gamma for scale-tanh
  gpus: [0]
  ##TODO: using tensorboard
  visdom_env: fashion_hash_net
  visdom_title: fashion_hash_net_t3_allFashion_noSemantic
  checkpoints: ./checkpoints/fashion_hash_net_t3_allFashion_noSemantic
  optim_param:
    name: SGD
    # lr: [5, 0.001, 0.005, 0.005, 0.01] # learning rate for each group
    lr: [10, 0.001, 0.01, 0.01, 0.1]
    weight_decay: 1.0e-06
    grad_param: { momentum: 0.9 } # setting for SGD
    lr_scheduler: ReduceLROnPlateau
    scheduler_param:
      { cooldown: 10, factor: 0.5, patience: 10, threshold: 0.05 }

log_file: logs/train/fashion_hash_net_t3_allFashion_noSemantic.log
log_level: DEBUG
